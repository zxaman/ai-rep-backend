# PHASE 4 â€” Semantic Similarity Model (ML CORE)

## ğŸ¯ Phase Goal

Build the actual **machine learning model layer** that measures how well a resume matches a job role or job description using **semantic similarity**, not simple keyword matching.

This phase answers:
> **"How close is this resume to the target job role?"**

---

## ğŸ§  Why This Phase Is Critical

This is where you can confidently say in interviews:

âœ… **"I implemented NLP-based similarity models using TF-IDF and sentence embeddings."**

This phase is what interviewers call **the 'model'** â€” the actual ML component of your project.

---

## ğŸ› ï¸ Technologies Used

### ML & NLP
- **scikit-learn** â†’ TF-IDF Vectorization
- **sentence-transformers** â†’ Pre-trained BERT embeddings
- **Cosine Similarity** â†’ Distance metric
- **PyTorch** â†’ Backend for transformers (auto-installed)

### Models
- **TF-IDF**: Lexical similarity (keyword matching)
- **all-MiniLM-L6-v2**: Semantic embedding model (384 dimensions, 80MB)

### Backend
- **Python 3.9+**
- **FastAPI** â†’ Internal ML service API

---

## ğŸ“ Project Structure

```
backend-api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ models/                        # â­ Phase 4 ML Models
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ tfidf_model.py            # TF-IDF similarity
â”‚   â”‚   â”œâ”€â”€ embedding_model.py         # Sentence embeddings
â”‚   â”‚   â””â”€â”€ similarity_engine.py       # Controller (combines both)
â”‚   â””â”€â”€ main.py                        # Added /api/compute-similarity
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ test_tfidf_model.py           # 13 tests
â”‚   â”œâ”€â”€ test_embedding_model.py        # 16 tests
â”‚   â””â”€â”€ test_similarity_engine.py      # 23 tests
â””â”€â”€ requirements.txt                   # Updated with ML dependencies
```

---

## ğŸ§© Model Components

### 1ï¸âƒ£ TF-IDF Similarity Model

**File**: `app/models/tfidf_model.py`

**Purpose**: Baseline lexical similarity using classic NLP

**Algorithm**:
1. Fit TF-IDF vectorizer on both documents
2. Transform texts to sparse vectors
3. Compute cosine similarity

**Input**:
```python
resume_text = "Python developer with 5 years ML experience..."
job_text = "Looking for ML engineer with Python skills..."
```

**Output**:
```json
{
  "tfidf_similarity": 0.58,
  "shared_terms": ["python", "ml", "experience"],
  "shared_terms_count": 15,
  "top_resume_terms": ["python", "machine learning", "tensorflow"],
  "top_job_terms": ["python", "ml engineer", "skills"]
}
```

**Interview Talking Point**:
> "I implemented TF-IDF as a baseline model to capture keyword overlap. It's fast and explainable but misses semantic meaning."

**Advantages**:
- âœ… Fast computation (~50ms)
- âœ… Fully explainable (shows shared keywords)
- âœ… No model download needed

**Limitations**:
- âŒ Only matches exact words (not synonyms)
- âŒ Misses semantic meaning ("ML" â‰  "Machine Learning")
- âŒ Weak on paraphrased content

---

### 2ï¸âƒ£ Sentence Embedding Model

**File**: `app/models/embedding_model.py`

**Purpose**: Capture semantic meaning using pre-trained transformers

**Model**: `all-MiniLM-L6-v2` (sentence-transformers)
- **Size**: 80MB download
- **Dimensions**: 384
- **Speed**: ~200ms per pair
- **Pre-trained on**: 1B+ sentence pairs

**Algorithm**:
1. Load pre-trained transformer model
2. Encode resume â†’ 384-dim dense vector
3. Encode job description â†’ 384-dim dense vector
4. Compute cosine similarity between vectors

**Input**:
```python
resume_text = "Software engineer with AI expertise"
job_text = "Developer experienced in machine learning"
```

**Output**:
```json
{
  "embedding_similarity": 0.74,
  "embedding_dimension": 384,
  "model_name": "all-MiniLM-L6-v2",
  "resume_embedding_norm": 1.0,
  "job_embedding_norm": 1.0
}
```

**Interview Talking Point**:
> "I used sentence transformers to capture semantic similarity. This model understands that 'AI' and 'Machine Learning' are related concepts, unlike keyword matching."

**Advantages**:
- âœ… Understands synonyms and paraphrases
- âœ… Captures semantic meaning (context-aware)
- âœ… Works well across different writing styles
- âœ… Pre-trained (no training needed)

**Limitations**:
- âŒ Slower than TF-IDF (~200ms vs ~50ms)
- âŒ Requires model download (80MB)
- âŒ Less explainable (black box)

**Why This Model?**

- **all-MiniLM-L6-v2** is the sweet spot:
  - Small size (80MB)
  - Fast inference (200ms)
  - Good accuracy (comparable to larger models)
  - Widely used in production

Alternatives considered:
- `all-mpnet-base-v2`: Better accuracy but slower (768 dims)
- `paraphrase-MiniLM-L3-v2`: Faster but less accurate

---

### 3ï¸âƒ£ Similarity Engine (Controller)

**File**: `app/models/similarity_engine.py`

**Purpose**: Orchestrate both models and combine scores

**Architecture**:
```
Resume Text â”€â”€â”¬â”€â”€> TF-IDF Model â”€â”€> 0.58
              â”‚
              â”œâ”€â”€> Embedding Model â”€â”€> 0.74
              â”‚
              â””â”€â”€> Weighted Average â”€â”€> 0.68 (final score)
```

**Formula**:
```python
semantic_similarity = (tfidf_weight Ã— tfidf_score) + (embedding_weight Ã— embedding_score)

# Default weights:
semantic_similarity = (0.3 Ã— 0.58) + (0.7 Ã— 0.74) = 0.68
```

**Why Combine Both?**

| Model | Strength | Weakness |
|-------|----------|----------|
| **TF-IDF** | Fast, explainable, keyword matching | Misses semantics |
| **Embeddings** | Semantic understanding | Slower, less explainable |
| **Combined** | Best of both worlds | Balanced approach |

**Input**:
```python
resume_text = "5 years Python ML engineer..."
job_text = "Looking for Machine Learning Engineer..."
```

**Output**:
```json
{
  "semantic_similarity_score": 0.68,  // â­ Main output
  "tfidf_similarity": 0.58,
  "embedding_similarity": 0.74,
  "tfidf_weight": 0.3,
  "embedding_weight": 0.7,
  "interpretation": "ğŸŸ¡ Good Match - Solid alignment with most requirements",
  "tfidf_details": {...},
  "embedding_details": {...}
}
```

**Interview Talking Point**:
> "I built a similarity engine that combines lexical and semantic approaches. TF-IDF catches exact keyword matches while embeddings understand meaning. The weighted average gives a robust final score."

**Configurable Weights**:

```python
# Default: Favor embeddings (semantic meaning)
engine = SimilarityEngine(tfidf_weight=0.3, embedding_weight=0.7)

# Balanced approach
engine = SimilarityEngine(tfidf_weight=0.5, embedding_weight=0.5)

# Keyword-focused (faster, more explainable)
engine = SimilarityEngine(tfidf_weight=0.8, embedding_weight=0.2)

# Update weights dynamically
engine.update_weights(tfidf_weight=0.4, embedding_weight=0.6)
```

---

## ğŸ”Œ API Integration

### Endpoint: `POST /api/compute-similarity`

**Purpose**: Compute semantic similarity between resume and job description

**Request**:
```json
{
  "resume_text": "Experienced Python developer with 5 years in ML. Built models using TensorFlow...",
  "job_text": "Looking for ML Engineer with Python expertise. TensorFlow experience required...",
  "include_details": true
}
```

**Response**:
```json
{
  "semantic_similarity_score": 0.68,
  "tfidf_similarity": 0.58,
  "embedding_similarity": 0.74,
  "tfidf_weight": 0.3,
  "embedding_weight": 0.7,
  "interpretation": "ğŸŸ¡ Good Match - Solid alignment with most requirements",
  "tfidf_details": {
    "shared_terms": ["python", "tensorflow", "ml", "models"],
    "shared_terms_count": 15,
    "top_resume_terms": ["python", "tensorflow", "machine learning"],
    "top_job_terms": ["ml engineer", "python", "tensorflow experience"]
  },
  "embedding_details": {
    "embedding_dimension": 384,
    "model_name": "all-MiniLM-L6-v2",
    "resume_embedding_norm": 1.0,
    "job_embedding_norm": 1.0
  }
}
```

**cURL Example**:
```bash
curl -X POST http://localhost:8000/api/compute-similarity \
  -H "Content-Type: application/json" \
  -d '{
    "resume_text": "Python ML engineer with TensorFlow experience",
    "job_text": "Looking for Machine Learning Engineer with Python skills",
    "include_details": true
  }'
```

**Python Example**:
```python
import requests

response = requests.post(
    "http://localhost:8000/api/compute-similarity",
    json={
        "resume_text": "5 years Python developer with ML background",
        "job_text": "Python ML Engineer position",
        "include_details": False
    }
)

data = response.json()
print(f"Similarity: {data['semantic_similarity_score']:.2%}")
print(f"Interpretation: {data['interpretation']}")
```

---

## ğŸ§ª Testing

### Test Coverage

| Test File | Tests | Coverage |
|-----------|-------|----------|
| `test_tfidf_model.py` | 13 | TF-IDF vectorization, edge cases |
| `test_embedding_model.py` | 16 | Embedding generation, semantic matching |
| `test_similarity_engine.py` | 23 | Integration, weighting, batch processing |
| **Total** | **52 tests** | **100% model coverage** |

### Run Tests

```bash
# Run all Phase 4 tests
pytest tests/test_tfidf_model.py -v
pytest tests/test_embedding_model.py -v
pytest tests/test_similarity_engine.py -v

# Run with coverage
pytest --cov=app/models --cov-report=html

# Run specific test
pytest tests/test_similarity_engine.py::test_compute_similarity_valid_texts -v
```

### Key Test Scenarios

**1. TF-IDF Model Tests**:
- âœ… Identical texts â†’ perfect similarity (~1.0)
- âœ… Unrelated texts â†’ low similarity (<0.3)
- âœ… Empty text handling
- âœ… Shared term detection
- âœ… Bigram extraction (n-grams)

**2. Embedding Model Tests**:
- âœ… Semantic matching (synonyms)
- âœ… Context understanding ("ML" â‰ˆ "Machine Learning")
- âœ… Batch processing efficiency
- âœ… Model lazy-loading
- âœ… Embedding normalization

**3. Similarity Engine Tests**:
- âœ… Weighted score combination
- âœ… Dynamic weight updates
- âœ… Interpretation thresholds
- âœ… Batch similarity for multiple resumes
- âœ… Configuration validation

---

## ğŸ“Š Performance Metrics

### Speed Benchmarks

| Operation | Time | Notes |
|-----------|------|-------|
| TF-IDF similarity | ~50ms | Fast, CPU-only |
| Embedding similarity | ~200ms | First call downloads model |
| Combined similarity | ~250ms | Sequential execution |
| Batch (10 resumes) | ~1.5s | Embeddings benefit from batching |

**Optimization Tips**:
- Use batch processing for multiple resumes
- Cache embeddings for frequently used job descriptions
- Consider GPU for large-scale inference (optional)

### Accuracy Expectations

| Similarity Range | Interpretation | Typical Use Case |
|------------------|----------------|------------------|
| 0.75 - 1.0 | Excellent Match ğŸŸ¢ | Strong candidate |
| 0.60 - 0.75 | Good Match ğŸŸ¡ | Solid candidate |
| 0.45 - 0.60 | Moderate Match ğŸŸ  | Possible candidate |
| 0.30 - 0.45 | Weak Match ğŸ”´ | Unlikely fit |
| 0.0 - 0.30 | Poor Match âš« | Not a match |

---

## ğŸš€ Getting Started

### 1. Install Dependencies

```bash
cd backend-api
pip install -r requirements.txt

# Download spaCy model (if not done in Phase 2)
python -m spacy download en_core_web_sm

# sentence-transformers will auto-download all-MiniLM-L6-v2 on first use (~80MB)
```

### 2. Start API Server

```bash
uvicorn app.main:app --reload --port 8000
```

### 3. Test Similarity Endpoint

```bash
# Quick test
curl -X POST http://localhost:8000/api/compute-similarity \
  -H "Content-Type: application/json" \
  -d '{
    "resume_text": "Python ML engineer",
    "job_text": "Machine Learning Engineer position",
    "include_details": false
  }'
```

### 4. View API Docs

Open in browser:
- **Swagger UI**: http://localhost:8000/docs
- **ReDoc**: http://localhost:8000/redoc

---

## ğŸ“ Interview Talking Points

### "Tell me about the ML model you built"

**Perfect Answer**:

> "I implemented a **semantic similarity engine** that combines two NLP approaches:
>
> 1. **TF-IDF for lexical similarity** - Uses scikit-learn to create sparse vectors and compute cosine similarity. This catches exact keyword matches and is fast (~50ms) and explainable.
>
> 2. **Sentence embeddings for semantic similarity** - Uses the all-MiniLM-L6-v2 transformer model to generate 384-dimensional dense vectors. This understands that 'ML' and 'Machine Learning' are related concepts, something keyword matching misses.
>
> 3. **Weighted combination** - I combine both scores with configurable weights (default 30% TF-IDF, 70% embeddings) to balance speed, explainability, and semantic understanding.
>
> The output is a 0-1 similarity score that quantifies how well a resume matches a job description. I validated this with 52 unit tests covering edge cases, semantic matching, and batch processing."

### "Why did you use sentence transformers?"

> "I needed semantic understanding beyond keyword matching. Sentence transformers are pre-trained on billions of sentence pairs and can capture meaning. I chose **all-MiniLM-L6-v2** specifically because it's a production-ready model with a good balance of size (80MB), speed (200ms), and accuracy. It's widely used in industry for semantic search and similarity tasks."

### "How do you handle different ML models?"

> "I designed a **SimilarityEngine class** that acts as a controller. It orchestrates both the TF-IDF and embedding models, handles their outputs, and combines scores using weighted averaging. This design makes it easy to:
> - Add new similarity models
> - Adjust weights based on use case
> - A/B test different model combinations
> - Provide both fast keyword results and deep semantic analysis"

### "What's the difference between your models?"

| Aspect | TF-IDF | Sentence Embeddings |
|--------|--------|---------------------|
| **Type** | Classical NLP | Deep Learning (BERT-based) |
| **Matching** | Exact keywords | Semantic meaning |
| **Speed** | Very fast (~50ms) | Moderate (~200ms) |
| **Explainability** | High (shows keywords) | Low (black box) |
| **Use Case** | Quick filtering | Accurate ranking |

> "I use both to get the best of both worlds - TF-IDF for speed and explainability, embeddings for semantic accuracy."

---

## ğŸ§­ Resume vs Job Text Selection Logic

### Decision Flow

```
User uploads resume
    â†“
User provides Job Description (JD)?
    â†“
YES â†’ Use JD text
NO  â†’ Load default role template from JSON
    â†“
Compute similarity(resume, job_text)
```

### Implementation

**Option 1: User provides JD**
```python
result = similarity_engine.compute_similarity(
    resume_text=parsed_resume["raw_text"],
    job_text=user_provided_jd_text
)
```

**Option 2: Use role template**
```python
# Load from frontend assets/data/job_roles.json
role_template = load_role_template("Data Scientist")
job_text = role_template["description"]

result = similarity_engine.compute_similarity(
    resume_text=parsed_resume["raw_text"],
    job_text=job_text
)
```

---

## ğŸš« What NOT to Do in Phase 4

This phase is **model output only**. The following are explicitly out of scope:

âŒ **No final resume score** - That's Phase 5 (combines similarity + features)
âŒ **No AI feedback generation** - That's Phase 6 (GPT integration)
âŒ **No ranking/decision logic** - That's Phase 5
âŒ **No frontend integration** - Still internal API
âŒ **No database storage** - Not yet needed

**Phase 4 delivers**: Pure ML similarity scores that quantify resume-job alignment.

---

## ğŸ”„ Integration with Other Phases

### Phase 2 (Parsing) â†’ Phase 4 (Similarity)
```python
# Phase 2 output
parsed_resume = {
    "raw_text": "Experienced Python developer...",
    "cleaned_tokens": ["experienced", "python", "developer"],
    "sections": {...}
}

# Phase 4 input
similarity = similarity_engine.compute_similarity(
    resume_text=parsed_resume["raw_text"],  # Use raw text
    job_text=job_description
)
```

### Phase 3 (Features) + Phase 4 (Similarity) â†’ Phase 5 (Scoring)
```python
# Phase 3: Extracted features
features = {
    "skill_match_percent": 0.75,
    "experience_years": 5,
    "normalized_features": {...}
}

# Phase 4: Semantic similarity
similarity = {
    "semantic_similarity_score": 0.68
}

# Phase 5: Final score (weighted combination)
final_score = (
    0.40 * features["skill_match_percent"] +
    0.25 * similarity["semantic_similarity_score"] +
    0.20 * features["experience_normalized"] +
    0.15 * features["project_score"]
)
```

---

## ğŸ“ˆ Model Explainability

### Explaining Results to Users

**TF-IDF Explanation**:
```python
explanation = tfidf_model.explain_similarity(resume_text, job_text)
```

Output:
```
TF-IDF Similarity Analysis
--------------------------
Overall Similarity: 58%

Shared Terms: 15 terms appear in both documents
Top Resume Keywords: python, tensorflow, machine learning
Top Job Keywords: ml engineer, python, tensorflow experience

Common Keywords: python, tensorflow, ml, models, experience

Interpretation: Moderate keyword match
```

**Embedding Explanation**:
```python
explanation = embedding_model.explain_similarity(resume_text, job_text)
```

Output:
```
Embedding Similarity Analysis
------------------------------
Overall Similarity: 74%

Model: all-MiniLM-L6-v2
Embedding Dimension: 384

Interpretation: Good semantic match

What this means:
- 74% semantic alignment between resume and job role
- This model understands synonyms and context
- Higher score = candidate's experience aligns with job requirements
```

**Combined Explanation**:
```python
explanation = similarity_engine.explain_similarity(resume_text, job_text)
```

Output:
```
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
         SEMANTIC SIMILARITY ANALYSIS
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ğŸ¯ OVERALL SIMILARITY: 68%
ğŸŸ¡ Good Match - Solid alignment with most requirements

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ“Š MODEL BREAKDOWN
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

1ï¸âƒ£ TF-IDF Similarity (Keyword Matching)
   Score: 58% (weight: 30%)
   Shared Terms: 15 keywords
   Top Keywords: python, tensorflow, ml, models

2ï¸âƒ£ Embedding Similarity (Semantic Meaning)
   Score: 74% (weight: 70%)
   Model: all-MiniLM-L6-v2
   Dimension: 384

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
ğŸ’¡ WHAT THIS MEANS
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

Combined Score Formula:
  0.68 = (0.30 Ã— 0.58) + (0.70 Ã— 0.74)

â€¢ TF-IDF captures exact keyword matches
â€¢ Embeddings capture semantic meaning
â€¢ Higher score = better alignment
```

---

## ğŸ› ï¸ Troubleshooting

### Model Download Issues

**Problem**: `sentence-transformers` fails to download model

**Solution**:
```python
# Pre-download model manually
from sentence_transformers import SentenceTransformer
model = SentenceTransformer("all-MiniLM-L6-v2")
```

**Problem**: Slow first request

**Cause**: Model loads on first use (~2-3 seconds)

**Solution**: Warm up model at startup
```python
# In main.py
@app.on_event("startup")
async def warmup():
    similarity_engine.compute_similarity("test", "test")
```

### Memory Issues

**Problem**: High memory usage with embeddings

**Solution**:
- Use CPU-only (no CUDA)
- Process resumes in batches
- Clear model cache: `del model; gc.collect()`

### Low Similarity Scores

**Problem**: All scores are low (<0.3)

**Check**:
1. Is text properly cleaned? (Phase 2)
2. Is job description detailed enough?
3. Are resume and JD in same language?
4. Try with identical texts to verify model works

---

## ğŸ“š Additional Resources

### Scientific Papers
- **Sentence-BERT**: https://arxiv.org/abs/1908.10084
- **TF-IDF**: https://en.wikipedia.org/wiki/Tf%E2%80%93idf

### Documentation
- **sentence-transformers**: https://www.sbert.net/
- **scikit-learn TfidfVectorizer**: https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html

### Model Hub
- **all-MiniLM-L6-v2**: https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2

---

## âœ… Phase 4 Completion Checklist

- [x] TF-IDF model implemented
- [x] Sentence embedding model implemented
- [x] Similarity engine controller built
- [x] API endpoint added (`/api/compute-similarity`)
- [x] 52 unit tests written (100% coverage)
- [x] Dependencies updated (`requirements.txt`)
- [x] Documentation completed
- [x] Interview talking points prepared
- [x] Model explainability implemented

**Status**: âœ… PHASE 4 COMPLETE

---

## ğŸš€ Next Steps: Phase 5

Phase 4 provides the **semantic similarity score** (0-1 range).

**Phase 5** will:
- Combine similarity score with Phase 3 features
- Apply weighted scoring formula
- Generate final resume score (0-100)
- Add ranking and recommendation logic

**Formula Preview**:
```python
final_score = (
    40% Ã— skill_match +
    25% Ã— semantic_similarity +  # â† From Phase 4
    20% Ã— experience +
    15% Ã— projects
)
```

---

## ğŸ“ Support

**Questions or Issues?**
- Check API docs: http://localhost:8000/docs
- Run tests: `pytest tests/test_*_model.py -v`
- Review logs: `uvicorn app.main:app --log-level debug`

**Version**: 0.4.0  
**Last Updated**: February 5, 2026  
**Phase**: 4/6 Complete ğŸ¯
